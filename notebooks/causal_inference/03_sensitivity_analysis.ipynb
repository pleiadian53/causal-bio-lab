{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis: Robustness to Unmeasured Confounding\n",
    "\n",
    "This notebook covers **sensitivity analysis** methods for assessing how robust causal conclusions are to potential unmeasured confounding.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Understand why sensitivity analysis is essential for causal inference\n",
    "2. Learn the E-value approach for unmeasured confounding\n",
    "3. Implement Rosenbaum bounds for matched studies\n",
    "4. Apply sensitivity analysis to biological examples\n",
    "5. Interpret and report sensitivity analysis results\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Treatment effect estimation (`01_treatment_effects.ipynb`)\n",
    "- Causal graphs and confounding (`02_causal_graphs.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Why Sensitivity Analysis?\n",
    "\n",
    "### The Fundamental Problem\n",
    "\n",
    "All causal inference from observational data relies on the **no unmeasured confounding** assumption:\n",
    "\n",
    "> Given the measured covariates, treatment assignment is independent of potential outcomes.\n",
    "\n",
    "This assumption is **untestable** from the data alone. We can never prove there isn't an unmeasured confounder.\n",
    "\n",
    "### What Sensitivity Analysis Does\n",
    "\n",
    "Instead of assuming no unmeasured confounding, sensitivity analysis asks:\n",
    "\n",
    "> **How strong would unmeasured confounding need to be to explain away our findings?**\n",
    "\n",
    "If the answer is \"implausibly strong,\" we gain confidence in our conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate example data with known confounding structure\n",
    "def generate_confounded_data(n=2000, \n",
    "                              true_effect=0.5,\n",
    "                              measured_confounding=0.6,\n",
    "                              unmeasured_confounding=0.0,\n",
    "                              seed=42):\n",
    "    \"\"\"\n",
    "    Generate data with both measured and unmeasured confounding.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Sample size\n",
    "    true_effect : float\n",
    "        True causal effect of treatment on outcome\n",
    "    measured_confounding : float\n",
    "        Strength of measured confounder (Z)\n",
    "    unmeasured_confounding : float\n",
    "        Strength of unmeasured confounder (U)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with columns: Z (measured), U (unmeasured), T (treatment), Y (outcome)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Measured confounder\n",
    "    Z = np.random.normal(0, 1, n)\n",
    "    \n",
    "    # Unmeasured confounder\n",
    "    U = np.random.normal(0, 1, n)\n",
    "    \n",
    "    # Treatment probability depends on both confounders\n",
    "    logit_T = measured_confounding * Z + unmeasured_confounding * U\n",
    "    prob_T = 1 / (1 + np.exp(-logit_T))\n",
    "    T = np.random.binomial(1, prob_T)\n",
    "    \n",
    "    # Outcome depends on treatment and both confounders\n",
    "    Y = (true_effect * T + \n",
    "         measured_confounding * Z + \n",
    "         unmeasured_confounding * U + \n",
    "         np.random.normal(0, 0.5, n))\n",
    "    \n",
    "    return pd.DataFrame({'Z': Z, 'U': U, 'T': T, 'Y': Y})\n",
    "\n",
    "# Generate data with no unmeasured confounding\n",
    "df_no_unmeasured = generate_confounded_data(unmeasured_confounding=0.0)\n",
    "\n",
    "# Generate data with unmeasured confounding\n",
    "df_with_unmeasured = generate_confounded_data(unmeasured_confounding=0.8)\n",
    "\n",
    "print(\"Data generated with true effect = 0.5\")\n",
    "print(f\"No unmeasured confounding: n={len(df_no_unmeasured)}\")\n",
    "print(f\"With unmeasured confounding: n={len(df_with_unmeasured)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate effects with and without adjusting for unmeasured confounder\n",
    "def estimate_ate(df, adjust_for):\n",
    "    \"\"\"Estimate ATE using linear regression with specified covariates.\"\"\"\n",
    "    X = df[['T'] + adjust_for]\n",
    "    y = df['Y']\n",
    "    lr = LinearRegression().fit(X, y)\n",
    "    return lr.coef_[0]  # Coefficient on T\n",
    "\n",
    "print(\"Effect Estimates (True effect = 0.5)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# No unmeasured confounding case\n",
    "print(\"\\nCase 1: No unmeasured confounding\")\n",
    "naive_1 = estimate_ate(df_no_unmeasured, [])\n",
    "adjusted_Z_1 = estimate_ate(df_no_unmeasured, ['Z'])\n",
    "adjusted_ZU_1 = estimate_ate(df_no_unmeasured, ['Z', 'U'])\n",
    "print(f\"  Naive (no adjustment):     {naive_1:.3f}\")\n",
    "print(f\"  Adjusted for Z only:       {adjusted_Z_1:.3f} ✓\")\n",
    "print(f\"  Adjusted for Z and U:      {adjusted_ZU_1:.3f} ✓\")\n",
    "\n",
    "# With unmeasured confounding case\n",
    "print(\"\\nCase 2: With unmeasured confounding (U not measured)\")\n",
    "naive_2 = estimate_ate(df_with_unmeasured, [])\n",
    "adjusted_Z_2 = estimate_ate(df_with_unmeasured, ['Z'])\n",
    "adjusted_ZU_2 = estimate_ate(df_with_unmeasured, ['Z', 'U'])\n",
    "print(f\"  Naive (no adjustment):     {naive_2:.3f}\")\n",
    "print(f\"  Adjusted for Z only:       {adjusted_Z_2:.3f} ← BIASED (U not measured)\")\n",
    "print(f\"  Adjusted for Z and U:      {adjusted_ZU_2:.3f} ✓ (oracle)\")\n",
    "\n",
    "print(\"\\n⚠️  When U is unmeasured, adjusting for Z alone leaves residual bias!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: The E-value\n",
    "\n",
    "The **E-value** (VanderWeele & Ding, 2017) quantifies the minimum strength of association that an unmeasured confounder would need to have with both treatment and outcome to fully explain away an observed effect.\n",
    "\n",
    "### Definition\n",
    "\n",
    "For a risk ratio RR, the E-value is:\n",
    "\n",
    "$$E = RR + \\sqrt{RR \\times (RR - 1)}$$\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "The E-value is the minimum risk ratio that an unmeasured confounder would need to have with BOTH:\n",
    "1. The treatment (given measured covariates)\n",
    "2. The outcome (given treatment and measured covariates)\n",
    "\n",
    "to explain away the observed association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_e_value(rr):\n",
    "    \"\"\"\n",
    "    Compute the E-value for a given risk ratio.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rr : float\n",
    "        Risk ratio (must be >= 1; if < 1, use 1/rr)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float : E-value\n",
    "    \"\"\"\n",
    "    if rr < 1:\n",
    "        rr = 1 / rr\n",
    "    return rr + np.sqrt(rr * (rr - 1))\n",
    "\n",
    "def compute_e_value_for_ci(rr, rr_lower):\n",
    "    \"\"\"\n",
    "    Compute E-value for point estimate and confidence interval bound.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rr : float\n",
    "        Point estimate of risk ratio\n",
    "    rr_lower : float\n",
    "        Lower bound of confidence interval (closer to null)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple : (E-value for point estimate, E-value for CI bound)\n",
    "    \"\"\"\n",
    "    e_point = compute_e_value(rr)\n",
    "    \n",
    "    # For CI bound, if it crosses 1, E-value is 1\n",
    "    if rr_lower <= 1:\n",
    "        e_ci = 1.0\n",
    "    else:\n",
    "        e_ci = compute_e_value(rr_lower)\n",
    "    \n",
    "    return e_point, e_ci\n",
    "\n",
    "# Example E-values for different effect sizes\n",
    "print(\"E-values for Different Risk Ratios\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Risk Ratio':<15} {'E-value':<15} {'Interpretation'}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for rr in [1.5, 2.0, 3.0, 5.0, 10.0]:\n",
    "    e = compute_e_value(rr)\n",
    "    print(f\"{rr:<15.1f} {e:<15.2f} Confounder needs RR≥{e:.1f} with both T and Y\")\n",
    "\n",
    "print(\"\\nInterpretation: Higher E-values = more robust to unmeasured confounding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize E-value as a function of risk ratio\n",
    "rr_range = np.linspace(1.01, 10, 100)\n",
    "e_values = [compute_e_value(rr) for rr in rr_range]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(rr_range, e_values, 'b-', linewidth=2)\n",
    "plt.xlabel('Observed Risk Ratio', fontsize=12)\n",
    "plt.ylabel('E-value', fontsize=12)\n",
    "plt.title('E-value as a Function of Observed Risk Ratio', fontsize=14)\n",
    "\n",
    "# Add reference lines\n",
    "for rr, label in [(2, 'RR=2'), (3, 'RR=3'), (5, 'RR=5')]:\n",
    "    e = compute_e_value(rr)\n",
    "    plt.axvline(rr, color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.axhline(e, color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.plot(rr, e, 'ro', markersize=8)\n",
    "    plt.annotate(f'{label}\\nE={e:.1f}', (rr+0.1, e+0.3), fontsize=10)\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E-value contour plot: What combinations of confounder-treatment and confounder-outcome\n",
    "# associations could explain away an observed effect?\n",
    "\n",
    "def bias_factor(rr_ut, rr_uy):\n",
    "    \"\"\"\n",
    "    Compute the maximum bias factor from an unmeasured confounder.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rr_ut : float\n",
    "        Risk ratio of U-T association\n",
    "    rr_uy : float\n",
    "        Risk ratio of U-Y association\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float : Maximum bias factor\n",
    "    \"\"\"\n",
    "    return (rr_ut * rr_uy) / (rr_ut + rr_uy - 1)\n",
    "\n",
    "# Create contour plot\n",
    "rr_ut_range = np.linspace(1.1, 5, 50)\n",
    "rr_uy_range = np.linspace(1.1, 5, 50)\n",
    "RR_UT, RR_UY = np.meshgrid(rr_ut_range, rr_uy_range)\n",
    "BIAS = bias_factor(RR_UT, RR_UY)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "contour = plt.contourf(RR_UT, RR_UY, BIAS, levels=20, cmap='RdYlBu_r')\n",
    "plt.colorbar(contour, label='Bias Factor')\n",
    "\n",
    "# Add contour lines for specific bias factors\n",
    "for bias_level in [1.5, 2.0, 3.0]:\n",
    "    cs = plt.contour(RR_UT, RR_UY, BIAS, levels=[bias_level], colors='black', linewidths=2)\n",
    "    plt.clabel(cs, inline=True, fontsize=10, fmt=f'Bias={bias_level}')\n",
    "\n",
    "plt.xlabel('RR(U→T): Confounder-Treatment Association', fontsize=12)\n",
    "plt.ylabel('RR(U→Y): Confounder-Outcome Association', fontsize=12)\n",
    "plt.title('Bias Factor from Unmeasured Confounding\\n(Combinations that could explain away observed effects)', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(\"- If observed RR=2, any combination in the 'Bias=2' contour could explain it away\")\n",
    "print(\"- Larger observed effects require stronger confounding to explain away\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Rosenbaum Bounds\n",
    "\n",
    "**Rosenbaum bounds** (Rosenbaum, 2002) provide a different approach to sensitivity analysis, particularly useful for matched studies.\n",
    "\n",
    "### The Idea\n",
    "\n",
    "In a matched study, we assume that matched pairs have the same probability of treatment. Rosenbaum bounds ask:\n",
    "\n",
    "> How much could treatment probabilities differ within matched pairs (due to unmeasured confounding) before our conclusions change?\n",
    "\n",
    "### The Γ Parameter\n",
    "\n",
    "Γ (gamma) represents the maximum odds ratio of treatment assignment between two units with the same observed covariates:\n",
    "\n",
    "$$\\frac{1}{\\Gamma} \\leq \\frac{P(T=1|X,U)/(1-P(T=1|X,U))}{P(T=1|X,U')/(1-P(T=1|X,U'))} \\leq \\Gamma$$\n",
    "\n",
    "- Γ = 1: No unmeasured confounding (perfect randomization within pairs)\n",
    "- Γ > 1: Some unmeasured confounding allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbaum_bounds(treated_outcomes, control_outcomes, gamma_values):\n",
    "    \"\"\"\n",
    "    Compute Rosenbaum bounds for a matched pair study.\n",
    "    \n",
    "    Uses the Wilcoxon signed-rank test framework.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    treated_outcomes : array\n",
    "        Outcomes for treated units in matched pairs\n",
    "    control_outcomes : array\n",
    "        Outcomes for control units in matched pairs\n",
    "    gamma_values : array\n",
    "        Values of Γ to evaluate\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with p-value bounds for each Γ\n",
    "    \"\"\"\n",
    "    # Compute pair differences\n",
    "    differences = treated_outcomes - control_outcomes\n",
    "    n_pairs = len(differences)\n",
    "    \n",
    "    # Rank absolute differences\n",
    "    abs_diff = np.abs(differences)\n",
    "    ranks = stats.rankdata(abs_diff)\n",
    "    \n",
    "    # Signs of differences\n",
    "    signs = np.sign(differences)\n",
    "    \n",
    "    # Observed test statistic (sum of positive ranks)\n",
    "    T_obs = np.sum(ranks[signs > 0])\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for gamma in gamma_values:\n",
    "        # Under Γ, the probability of a positive difference ranges from\n",
    "        # 1/(1+Γ) to Γ/(1+Γ)\n",
    "        p_plus_lower = 1 / (1 + gamma)\n",
    "        p_plus_upper = gamma / (1 + gamma)\n",
    "        \n",
    "        # Expected value and variance of T under null with bias\n",
    "        # (simplified approximation)\n",
    "        E_T_lower = np.sum(ranks) * p_plus_lower\n",
    "        E_T_upper = np.sum(ranks) * p_plus_upper\n",
    "        \n",
    "        Var_T = np.sum(ranks**2) * p_plus_upper * (1 - p_plus_upper)\n",
    "        \n",
    "        # Z-scores for bounds\n",
    "        z_lower = (T_obs - E_T_upper) / np.sqrt(Var_T)\n",
    "        z_upper = (T_obs - E_T_lower) / np.sqrt(Var_T)\n",
    "        \n",
    "        # P-values (one-sided, upper tail)\n",
    "        p_lower = 1 - stats.norm.cdf(z_lower)\n",
    "        p_upper = 1 - stats.norm.cdf(z_upper)\n",
    "        \n",
    "        results.append({\n",
    "            'gamma': gamma,\n",
    "            'p_lower': max(0, min(1, p_lower)),\n",
    "            'p_upper': max(0, min(1, p_upper))\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Generate matched pair data\n",
    "np.random.seed(42)\n",
    "n_pairs = 100\n",
    "\n",
    "# True treatment effect\n",
    "true_effect = 0.5\n",
    "\n",
    "# Matched pair outcomes\n",
    "baseline = np.random.normal(0, 1, n_pairs)\n",
    "treated = baseline + true_effect + np.random.normal(0, 0.5, n_pairs)\n",
    "control = baseline + np.random.normal(0, 0.5, n_pairs)\n",
    "\n",
    "# Compute bounds\n",
    "gamma_values = np.arange(1.0, 3.1, 0.1)\n",
    "bounds = rosenbaum_bounds(treated, control, gamma_values)\n",
    "\n",
    "print(\"Rosenbaum Bounds for Matched Pair Study\")\n",
    "print(\"=\"*50)\n",
    "print(bounds[bounds['gamma'].isin([1.0, 1.5, 2.0, 2.5, 3.0])].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Rosenbaum bounds\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.fill_between(bounds['gamma'], bounds['p_lower'], bounds['p_upper'], \n",
    "                 alpha=0.3, color='blue', label='P-value range')\n",
    "plt.plot(bounds['gamma'], bounds['p_lower'], 'b-', linewidth=2, label='Lower bound')\n",
    "plt.plot(bounds['gamma'], bounds['p_upper'], 'b--', linewidth=2, label='Upper bound')\n",
    "\n",
    "# Reference line at p=0.05\n",
    "plt.axhline(0.05, color='red', linestyle=':', linewidth=2, label='α = 0.05')\n",
    "\n",
    "# Find critical Γ where lower bound crosses 0.05\n",
    "critical_idx = np.where(bounds['p_upper'] > 0.05)[0]\n",
    "if len(critical_idx) > 0:\n",
    "    critical_gamma = bounds['gamma'].iloc[critical_idx[0]]\n",
    "    plt.axvline(critical_gamma, color='green', linestyle='--', alpha=0.7)\n",
    "    plt.annotate(f'Critical Γ ≈ {critical_gamma:.1f}', \n",
    "                 (critical_gamma + 0.1, 0.3), fontsize=12, color='green')\n",
    "\n",
    "plt.xlabel('Γ (Sensitivity Parameter)', fontsize=12)\n",
    "plt.ylabel('P-value', fontsize=12)\n",
    "plt.title('Rosenbaum Sensitivity Analysis\\nHow much unmeasured confounding to change conclusions?', fontsize=14)\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"- At Γ=1 (no unmeasured confounding), p-value is very small\")\n",
    "print(f\"- Results remain significant until Γ ≈ {critical_gamma:.1f}\")\n",
    "print(f\"- An unmeasured confounder would need to change treatment odds by {critical_gamma:.1f}x\")\n",
    "print(f\"  within matched pairs to explain away the effect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Sensitivity Analysis for Linear Models\n",
    "\n",
    "For continuous outcomes with linear models, we can derive explicit formulas for how unmeasured confounding affects estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_sensitivity_analysis(df, treatment_col, outcome_col, covariate_cols,\n",
    "                                 r2_tu_values, r2_uy_values):\n",
    "    \"\"\"\n",
    "    Sensitivity analysis for linear regression.\n",
    "    \n",
    "    Computes adjusted estimates for different strengths of unmeasured confounding,\n",
    "    parameterized by partial R² values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Data\n",
    "    treatment_col : str\n",
    "        Name of treatment column\n",
    "    outcome_col : str\n",
    "        Name of outcome column\n",
    "    covariate_cols : list\n",
    "        Names of measured covariate columns\n",
    "    r2_tu_values : array\n",
    "        Partial R² of U on T (given covariates)\n",
    "    r2_uy_values : array\n",
    "        Partial R² of U on Y (given T and covariates)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with adjusted estimates for each (r2_tu, r2_uy) combination\n",
    "    \"\"\"\n",
    "    # Fit observed model\n",
    "    X = df[[treatment_col] + covariate_cols]\n",
    "    y = df[outcome_col]\n",
    "    lr = LinearRegression().fit(X, y)\n",
    "    \n",
    "    # Observed estimate\n",
    "    beta_obs = lr.coef_[0]\n",
    "    \n",
    "    # Residual variance\n",
    "    y_pred = lr.predict(X)\n",
    "    sigma2_y = np.var(y - y_pred)\n",
    "    \n",
    "    # Residual variance of T given covariates\n",
    "    if covariate_cols:\n",
    "        lr_t = LinearRegression().fit(df[covariate_cols], df[treatment_col])\n",
    "        t_resid = df[treatment_col] - lr_t.predict(df[covariate_cols])\n",
    "    else:\n",
    "        t_resid = df[treatment_col] - df[treatment_col].mean()\n",
    "    sigma2_t = np.var(t_resid)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for r2_tu in r2_tu_values:\n",
    "        for r2_uy in r2_uy_values:\n",
    "            # Bias formula (Cinelli & Hazlett, 2020)\n",
    "            # bias = sqrt(r2_tu * r2_uy) * sigma_y / sigma_t * sign\n",
    "            # (simplified version assuming positive confounding)\n",
    "            \n",
    "            bias = np.sqrt(r2_tu * r2_uy * sigma2_y / sigma2_t)\n",
    "            \n",
    "            # Adjusted estimate (assuming positive confounding)\n",
    "            beta_adj_lower = beta_obs - bias\n",
    "            beta_adj_upper = beta_obs + bias\n",
    "            \n",
    "            results.append({\n",
    "                'r2_tu': r2_tu,\n",
    "                'r2_uy': r2_uy,\n",
    "                'beta_obs': beta_obs,\n",
    "                'bias': bias,\n",
    "                'beta_adj_lower': beta_adj_lower,\n",
    "                'beta_adj_upper': beta_adj_upper\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Apply to our data\n",
    "r2_values = np.array([0.01, 0.05, 0.10, 0.15, 0.20])\n",
    "\n",
    "sensitivity_results = linear_sensitivity_analysis(\n",
    "    df_with_unmeasured,\n",
    "    treatment_col='T',\n",
    "    outcome_col='Y',\n",
    "    covariate_cols=['Z'],\n",
    "    r2_tu_values=r2_values,\n",
    "    r2_uy_values=r2_values\n",
    ")\n",
    "\n",
    "print(\"Sensitivity Analysis Results\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Observed estimate (adjusting for Z only): {sensitivity_results['beta_obs'].iloc[0]:.3f}\")\n",
    "print(f\"True effect: 0.5\")\n",
    "print(\"\\nAdjusted estimates for different unmeasured confounding strengths:\")\n",
    "print(sensitivity_results[['r2_tu', 'r2_uy', 'bias', 'beta_adj_lower']].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contour plot of adjusted estimates\n",
    "r2_fine = np.linspace(0.01, 0.25, 50)\n",
    "R2_TU, R2_UY = np.meshgrid(r2_fine, r2_fine)\n",
    "\n",
    "# Compute bias for each combination\n",
    "beta_obs = sensitivity_results['beta_obs'].iloc[0]\n",
    "sigma2_y = 0.5**2  # Approximate\n",
    "sigma2_t = 0.25  # Approximate\n",
    "\n",
    "BIAS = np.sqrt(R2_TU * R2_UY * sigma2_y / sigma2_t)\n",
    "BETA_ADJ = beta_obs - BIAS\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "contour = plt.contourf(R2_TU, R2_UY, BETA_ADJ, levels=20, cmap='RdYlGn')\n",
    "plt.colorbar(contour, label='Adjusted Effect Estimate')\n",
    "\n",
    "# Add contour lines\n",
    "cs = plt.contour(R2_TU, R2_UY, BETA_ADJ, levels=[0, 0.5], colors=['red', 'blue'], linewidths=2)\n",
    "plt.clabel(cs, inline=True, fontsize=10, fmt='%.1f')\n",
    "\n",
    "plt.xlabel('Partial R² of U on T (given Z)', fontsize=12)\n",
    "plt.ylabel('Partial R² of U on Y (given T, Z)', fontsize=12)\n",
    "plt.title('Sensitivity Analysis: Adjusted Effect Estimates\\n(Red line = effect becomes 0)', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(\"- Green region: Effect remains positive after adjustment\")\n",
    "print(\"- Red region: Effect becomes negative (sign reversal)\")\n",
    "print(\"- Red contour line: Combinations that would explain away the effect entirely\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Biological Application - Drug Response Study\n",
    "\n",
    "Let's apply sensitivity analysis to a realistic biological scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a drug response study with potential unmeasured confounding\n",
    "def simulate_drug_study(n=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Simulate a drug response study.\n",
    "    \n",
    "    Measured covariates: age, baseline_expression\n",
    "    Unmeasured confounder: genetic_variant (affects both drug metabolism and response)\n",
    "    Treatment: drug_treatment\n",
    "    Outcome: tumor_response\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Measured covariates\n",
    "    age = np.random.normal(55, 10, n)\n",
    "    baseline_expression = np.random.normal(0, 1, n)\n",
    "    \n",
    "    # Unmeasured confounder (genetic variant affecting drug metabolism)\n",
    "    genetic_variant = np.random.binomial(1, 0.3, n)  # 30% have variant\n",
    "    \n",
    "    # Treatment assignment (not randomized - depends on covariates)\n",
    "    # Doctors more likely to prescribe to younger patients with higher expression\n",
    "    # Genetic variant also affects prescribing (pharmacogenomics)\n",
    "    logit_treat = (-0.03 * (age - 55) + \n",
    "                   0.5 * baseline_expression + \n",
    "                   0.8 * genetic_variant)  # Unmeasured confounding\n",
    "    prob_treat = 1 / (1 + np.exp(-logit_treat))\n",
    "    drug_treatment = np.random.binomial(1, prob_treat)\n",
    "    \n",
    "    # Outcome (tumor response)\n",
    "    # True drug effect = 2.0\n",
    "    # Genetic variant also affects response (independent of drug)\n",
    "    tumor_response = (2.0 * drug_treatment +  # True causal effect\n",
    "                      -0.02 * (age - 55) +\n",
    "                      0.3 * baseline_expression +\n",
    "                      1.5 * genetic_variant +  # Unmeasured confounding\n",
    "                      np.random.normal(0, 1, n))\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'age': age,\n",
    "        'baseline_expression': baseline_expression,\n",
    "        'genetic_variant': genetic_variant,  # Unmeasured in practice\n",
    "        'drug_treatment': drug_treatment,\n",
    "        'tumor_response': tumor_response\n",
    "    })\n",
    "\n",
    "df_drug = simulate_drug_study()\n",
    "\n",
    "print(\"Drug Response Study\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Sample size: {len(df_drug)}\")\n",
    "print(f\"Treated: {df_drug['drug_treatment'].sum()}\")\n",
    "print(f\"Control: {(1 - df_drug['drug_treatment']).sum()}\")\n",
    "print(f\"\\nTrue causal effect of drug: 2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate effects with different adjustment sets\n",
    "print(\"Effect Estimates\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Naive\n",
    "lr_naive = LinearRegression().fit(\n",
    "    df_drug[['drug_treatment']], \n",
    "    df_drug['tumor_response']\n",
    ")\n",
    "print(f\"Naive (no adjustment): {lr_naive.coef_[0]:.3f}\")\n",
    "\n",
    "# Adjusted for measured covariates\n",
    "lr_measured = LinearRegression().fit(\n",
    "    df_drug[['drug_treatment', 'age', 'baseline_expression']], \n",
    "    df_drug['tumor_response']\n",
    ")\n",
    "print(f\"Adjusted for age, expression: {lr_measured.coef_[0]:.3f}\")\n",
    "\n",
    "# Oracle (adjusted for unmeasured too)\n",
    "lr_oracle = LinearRegression().fit(\n",
    "    df_drug[['drug_treatment', 'age', 'baseline_expression', 'genetic_variant']], \n",
    "    df_drug['tumor_response']\n",
    ")\n",
    "print(f\"Oracle (+ genetic variant): {lr_oracle.coef_[0]:.3f}\")\n",
    "\n",
    "print(f\"\\nTrue effect: 2.0\")\n",
    "print(f\"\\nBias from unmeasured confounding: {lr_measured.coef_[0] - 2.0:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute E-value for the drug study\n",
    "# First, convert to risk ratio scale (approximate)\n",
    "\n",
    "# For continuous outcomes, we can use the \"approximate RR\" approach\n",
    "# RR ≈ exp(β / SD(Y))\n",
    "\n",
    "beta_obs = lr_measured.coef_[0]\n",
    "sd_y = df_drug['tumor_response'].std()\n",
    "\n",
    "# Approximate RR\n",
    "rr_approx = np.exp(beta_obs / sd_y)\n",
    "\n",
    "# E-value\n",
    "e_value = compute_e_value(rr_approx)\n",
    "\n",
    "print(\"E-value Analysis for Drug Study\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Observed effect (β): {beta_obs:.3f}\")\n",
    "print(f\"SD of outcome: {sd_y:.3f}\")\n",
    "print(f\"Approximate RR: {rr_approx:.2f}\")\n",
    "print(f\"E-value: {e_value:.2f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"An unmeasured confounder would need RR ≥ {e_value:.1f} with both\")\n",
    "print(f\"treatment and outcome to explain away this effect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to known confounders as benchmarks\n",
    "print(\"Benchmarking Against Known Confounders\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Effect of age on treatment\n",
    "lr_age_t = LogisticRegression().fit(\n",
    "    df_drug[['age']], \n",
    "    df_drug['drug_treatment']\n",
    ")\n",
    "or_age_t = np.exp(lr_age_t.coef_[0][0] * 10)  # Per 10 years\n",
    "\n",
    "# Effect of age on outcome\n",
    "lr_age_y = LinearRegression().fit(\n",
    "    df_drug[['age', 'drug_treatment']], \n",
    "    df_drug['tumor_response']\n",
    ")\n",
    "beta_age_y = lr_age_y.coef_[0] * 10  # Per 10 years\n",
    "\n",
    "print(f\"Age (per 10 years):\")\n",
    "print(f\"  OR for treatment: {or_age_t:.2f}\")\n",
    "print(f\"  Effect on outcome: {beta_age_y:.3f}\")\n",
    "\n",
    "# Effect of baseline expression on treatment\n",
    "lr_expr_t = LogisticRegression().fit(\n",
    "    df_drug[['baseline_expression']], \n",
    "    df_drug['drug_treatment']\n",
    ")\n",
    "or_expr_t = np.exp(lr_expr_t.coef_[0][0])\n",
    "\n",
    "# Effect of baseline expression on outcome\n",
    "lr_expr_y = LinearRegression().fit(\n",
    "    df_drug[['baseline_expression', 'drug_treatment']], \n",
    "    df_drug['tumor_response']\n",
    ")\n",
    "beta_expr_y = lr_expr_y.coef_[0]\n",
    "\n",
    "print(f\"\\nBaseline expression (per SD):\")\n",
    "print(f\"  OR for treatment: {or_expr_t:.2f}\")\n",
    "print(f\"  Effect on outcome: {beta_expr_y:.3f}\")\n",
    "\n",
    "print(f\"\\nE-value required: {e_value:.2f}\")\n",
    "print(f\"\\nConclusion: An unmeasured confounder would need to be MUCH stronger\")\n",
    "print(f\"than age or baseline expression to explain away the drug effect.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Reporting Sensitivity Analysis\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Always report sensitivity analysis** for observational causal claims\n",
    "2. **Use multiple methods** (E-value, Rosenbaum bounds, etc.)\n",
    "3. **Benchmark against measured confounders** - is the required confounding plausible?\n",
    "4. **Be honest about limitations** - sensitivity analysis doesn't prove causation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_analysis_report(effect_estimate, se, outcome_sd, \n",
    "                                 measured_confounders=None,\n",
    "                                 alpha=0.05):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive sensitivity analysis report.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    effect_estimate : float\n",
    "        Point estimate of causal effect\n",
    "    se : float\n",
    "        Standard error of estimate\n",
    "    outcome_sd : float\n",
    "        Standard deviation of outcome\n",
    "    measured_confounders : list of dicts, optional\n",
    "        Each dict has 'name', 'or_treatment', 'effect_outcome'\n",
    "    alpha : float\n",
    "        Significance level\n",
    "    \"\"\"\n",
    "    # Confidence interval\n",
    "    z = stats.norm.ppf(1 - alpha/2)\n",
    "    ci_lower = effect_estimate - z * se\n",
    "    ci_upper = effect_estimate + z * se\n",
    "    \n",
    "    # Approximate RR\n",
    "    rr_point = np.exp(effect_estimate / outcome_sd)\n",
    "    rr_lower = np.exp(ci_lower / outcome_sd)\n",
    "    \n",
    "    # E-values\n",
    "    e_point, e_ci = compute_e_value_for_ci(rr_point, rr_lower)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"SENSITIVITY ANALYSIS REPORT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\n1. EFFECT ESTIMATE\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"   Point estimate: {effect_estimate:.3f}\")\n",
    "    print(f\"   Standard error: {se:.3f}\")\n",
    "    print(f\"   95% CI: [{ci_lower:.3f}, {ci_upper:.3f}]\")\n",
    "    \n",
    "    print(\"\\n2. E-VALUE ANALYSIS\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"   Approximate RR: {rr_point:.2f}\")\n",
    "    print(f\"   E-value (point estimate): {e_point:.2f}\")\n",
    "    print(f\"   E-value (CI bound): {e_ci:.2f}\")\n",
    "    print(f\"\\n   Interpretation:\")\n",
    "    print(f\"   To explain away the point estimate, an unmeasured confounder\")\n",
    "    print(f\"   would need RR ≥ {e_point:.1f} with both treatment and outcome.\")\n",
    "    if e_ci > 1:\n",
    "        print(f\"   To move the CI to include the null, RR ≥ {e_ci:.1f} is needed.\")\n",
    "    else:\n",
    "        print(f\"   The CI already includes the null.\")\n",
    "    \n",
    "    if measured_confounders:\n",
    "        print(\"\\n3. BENCHMARK COMPARISONS\")\n",
    "        print(\"-\"*40)\n",
    "        print(f\"   {'Confounder':<20} {'OR(T)':<10} {'Effect(Y)':<10}\")\n",
    "        for conf in measured_confounders:\n",
    "            print(f\"   {conf['name']:<20} {conf['or_treatment']:<10.2f} {conf['effect_outcome']:<10.3f}\")\n",
    "        print(f\"\\n   Required E-value: {e_point:.2f}\")\n",
    "    \n",
    "    print(\"\\n4. CONCLUSION\")\n",
    "    print(\"-\"*40)\n",
    "    if e_point > 3:\n",
    "        print(\"   The effect appears ROBUST to unmeasured confounding.\")\n",
    "        print(\"   A very strong confounder would be needed to explain it away.\")\n",
    "    elif e_point > 2:\n",
    "        print(\"   The effect has MODERATE robustness to unmeasured confounding.\")\n",
    "        print(\"   A moderately strong confounder could potentially explain it.\")\n",
    "    else:\n",
    "        print(\"   The effect has LIMITED robustness to unmeasured confounding.\")\n",
    "        print(\"   Even weak confounders could potentially explain it away.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Generate report for drug study\n",
    "sensitivity_analysis_report(\n",
    "    effect_estimate=lr_measured.coef_[0],\n",
    "    se=0.15,  # Approximate SE\n",
    "    outcome_sd=df_drug['tumor_response'].std(),\n",
    "    measured_confounders=[\n",
    "        {'name': 'Age (per 10 yrs)', 'or_treatment': or_age_t, 'effect_outcome': beta_age_y},\n",
    "        {'name': 'Expression (per SD)', 'or_treatment': or_expr_t, 'effect_outcome': beta_expr_y}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Sensitivity analysis** quantifies robustness to unmeasured confounding\n",
    "2. **E-value** gives minimum confounder strength to explain away an effect\n",
    "3. **Rosenbaum bounds** show how much hidden bias is tolerable in matched studies\n",
    "4. **Benchmarking** against measured confounders helps assess plausibility\n",
    "\n",
    "### Practical Guidelines\n",
    "\n",
    "- Always perform sensitivity analysis for observational causal claims\n",
    "- Report E-values for both point estimates and confidence intervals\n",
    "- Compare required confounding to measured confounders\n",
    "- Be honest: sensitivity analysis doesn't prove causation\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- Sensitivity analysis assumes a specific form of confounding\n",
    "- Multiple unmeasured confounders may have complex interactions\n",
    "- \"Robust\" doesn't mean \"causal\" - it means \"hard to explain away\"\n",
    "\n",
    "### References\n",
    "\n",
    "- VanderWeele & Ding (2017). \"Sensitivity Analysis in Observational Research\"\n",
    "- Rosenbaum (2002). \"Observational Studies\"\n",
    "- Cinelli & Hazlett (2020). \"Making Sense of Sensitivity\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. **E-value interpretation**: A study finds RR=1.8 for a drug effect. Compute the E-value and interpret it.\n",
    "\n",
    "2. **Benchmarking**: In your own research, identify 2-3 measured confounders. How strong are their associations with treatment and outcome? Would an unmeasured confounder need to be stronger?\n",
    "\n",
    "3. **Simulation study**: Generate data with known unmeasured confounding. Apply sensitivity analysis and verify it correctly identifies the bias.\n",
    "\n",
    "4. **Reporting**: Write a sensitivity analysis paragraph for a hypothetical observational study in your field."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
