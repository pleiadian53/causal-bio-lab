{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural CATE Estimators: Siamese T-Learner vs JEPA-Style Learning\n",
    "\n",
    "This notebook benchmarks modern neural architectures for treatment effect estimation:\n",
    "\n",
    "1. **Siamese T-Learner**: Shared encoder with separate outcome heads\n",
    "2. **JEPA-Style Causal Learner**: Joint embedding predictive architecture with causal regularization\n",
    "3. **Baseline methods**: Standard T-Learner and S-Learner\n",
    "\n",
    "We evaluate on synthetic gene expression data with known ground truth treatment effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "\n",
    "from causalbiolab.estimation.cate import SLearner, TLearner\n",
    "from causalbiolab.estimation.neural_cate import (\n",
    "    SiameseTLearner,\n",
    "    JEPACausalLearner,\n",
    "    benchmark_neural_cate,\n",
    ")\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Plotting setup\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Check for GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Generate Synthetic Gene Expression Data\n",
    "\n",
    "We simulate a realistic gene expression dataset with:\n",
    "- **20,000 genes** (high-dimensional)\n",
    "- **Heterogeneous treatment effects** (τ varies by cell state)\n",
    "- **Confounding** (cell cycle affects both treatment and outcome)\n",
    "- **Known ground truth** for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gene_expression_data(\n",
    "    n_samples: int = 2000,\n",
    "    n_genes: int = 1000,\n",
    "    n_informative: int = 50,\n",
    "    effect_heterogeneity: float = 0.5,\n",
    "    noise_level: float = 0.1,\n",
    "    random_state: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate synthetic gene expression data with treatment effects.\n",
    "    \n",
    "    Data generating process:\n",
    "    1. Sample gene expression from log-normal (realistic for RNA-seq)\n",
    "    2. Define cell states based on first few PCs\n",
    "    3. Treatment assignment depends on cell state (confounding)\n",
    "    4. Treatment effect varies by cell state (heterogeneity)\n",
    "    \n",
    "    Returns:\n",
    "        X: Gene expression (n_samples, n_genes)\n",
    "        T: Treatment (n_samples,)\n",
    "        Y: Outcome (n_samples,)\n",
    "        tau_true: True CATE (n_samples,)\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    \n",
    "    # 1. Generate gene expression (log-normal)\n",
    "    # Most genes have low expression, few have high\n",
    "    X = rng.lognormal(mean=0, sigma=1.5, size=(n_samples, n_genes))\n",
    "    \n",
    "    # Add structure: some genes are correlated (gene modules)\n",
    "    n_modules = 10\n",
    "    genes_per_module = n_genes // n_modules\n",
    "    for i in range(n_modules):\n",
    "        start = i * genes_per_module\n",
    "        end = start + genes_per_module\n",
    "        module_factor = rng.randn(n_samples, 1)\n",
    "        X[:, start:end] += module_factor * 0.5\n",
    "    \n",
    "    # 2. Define cell states (first 3 PCs as proxy)\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=3)\n",
    "    cell_states = pca.fit_transform(X)\n",
    "    \n",
    "    # 3. Treatment assignment (confounded by cell state)\n",
    "    # Cells in certain states more likely to receive treatment\n",
    "    propensity_logit = 0.5 * cell_states[:, 0] - 0.3 * cell_states[:, 1]\n",
    "    propensity = 1 / (1 + np.exp(-propensity_logit))\n",
    "    T = rng.binomial(1, propensity)\n",
    "    \n",
    "    # 4. Outcome model with heterogeneous treatment effects\n",
    "    # Base outcome depends on informative genes\n",
    "    beta = rng.randn(n_informative)\n",
    "    Y_base = X[:, :n_informative] @ beta\n",
    "    \n",
    "    # Treatment effect varies by cell state\n",
    "    # tau(x) = base_effect + heterogeneity * f(cell_state)\n",
    "    base_effect = 2.0\n",
    "    tau_true = base_effect + effect_heterogeneity * (\n",
    "        cell_states[:, 0] ** 2 + cell_states[:, 1]\n",
    "    )\n",
    "    \n",
    "    # Observed outcome\n",
    "    Y = Y_base + T * tau_true + rng.normal(0, noise_level, n_samples)\n",
    "    \n",
    "    # Standardize\n",
    "    X = (X - X.mean(axis=0)) / (X.std(axis=0) + 1e-8)\n",
    "    Y = (Y - Y.mean()) / Y.std()\n",
    "    tau_true = (tau_true - tau_true.mean()) / tau_true.std()\n",
    "    \n",
    "    return X, T, Y, tau_true, cell_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "print(\"Generating synthetic gene expression data...\")\n",
    "X, T, Y, tau_true, cell_states = generate_gene_expression_data(\n",
    "    n_samples=2000,\n",
    "    n_genes=1000,  # Use 1000 for faster training, can increase to 20000\n",
    "    n_informative=50,\n",
    "    effect_heterogeneity=0.5,\n",
    "    noise_level=0.1,\n",
    ")\n",
    "\n",
    "print(f\"Data shape: X={X.shape}, T={T.shape}, Y={Y.shape}\")\n",
    "print(f\"Treatment balance: {T.mean():.2%} treated\")\n",
    "print(f\"True CATE range: [{tau_true.min():.2f}, {tau_true.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Cell states colored by treatment\n",
    "axes[0].scatter(cell_states[T==0, 0], cell_states[T==0, 1], \n",
    "                alpha=0.5, label='Control', s=20)\n",
    "axes[0].scatter(cell_states[T==1, 0], cell_states[T==1, 1], \n",
    "                alpha=0.5, label='Treated', s=20)\n",
    "axes[0].set_xlabel('PC1')\n",
    "axes[0].set_ylabel('PC2')\n",
    "axes[0].set_title('Cell States (Confounding)')\n",
    "axes[0].legend()\n",
    "\n",
    "# True CATE distribution\n",
    "axes[1].hist(tau_true, bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[1].axvline(tau_true.mean(), color='r', linestyle='--', \n",
    "                label=f'Mean = {tau_true.mean():.2f}')\n",
    "axes[1].set_xlabel('True CATE')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('True Treatment Effect Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "# CATE vs cell state\n",
    "scatter = axes[2].scatter(cell_states[:, 0], cell_states[:, 1], \n",
    "                          c=tau_true, cmap='RdYlBu_r', s=20, alpha=0.6)\n",
    "axes[2].set_xlabel('PC1')\n",
    "axes[2].set_ylabel('PC2')\n",
    "axes[2].set_title('True CATE by Cell State')\n",
    "plt.colorbar(scatter, ax=axes[2], label='True CATE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, T_train, T_test, Y_train, Y_test, tau_train, tau_test = train_test_split(\n",
    "    X, T, Y, tau_true, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples\")\n",
    "print(f\"Test: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Benchmark Methods\n",
    "\n",
    "We compare:\n",
    "1. **S-Learner** (baseline): Single model\n",
    "2. **T-Learner** (baseline): Two independent models\n",
    "3. **Siamese T-Learner** (ours): Shared encoder + separate heads\n",
    "4. **JEPA-Causal** (ours): Joint embedding with causal regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "models = {\n",
    "    'S-Learner': SLearner(),\n",
    "    'T-Learner': TLearner(),\n",
    "    'Siamese-T': SiameseTLearner(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dims=[256, 128, 64],\n",
    "        learning_rate=1e-3,\n",
    "        batch_size=128,\n",
    "        n_epochs=100,\n",
    "        device=device,\n",
    "        verbose=True,\n",
    "    ),\n",
    "    'JEPA-Causal': JEPACausalLearner(\n",
    "        input_dim=input_dim,\n",
    "        context_dim=128,\n",
    "        treatment_dim=32,\n",
    "        target_dim=64,\n",
    "        learning_rate=1e-3,\n",
    "        batch_size=128,\n",
    "        n_epochs=100,\n",
    "        lambda_inv=0.1,\n",
    "        device=device,\n",
    "        verbose=True,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models and collect results\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {name}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # Fit\n",
    "    model.fit(X_train, T_train, Y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    tau_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    rmse = np.sqrt(mean_squared_error(tau_test, tau_pred))\n",
    "    r2 = r2_score(tau_test, tau_pred)\n",
    "    mae = np.mean(np.abs(tau_test - tau_pred))\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'tau_pred': tau_pred,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'mae': mae,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTest Set Performance:\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  R²: {r2:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Method': list(results.keys()),\n",
    "    'RMSE': [r['rmse'] for r in results.values()],\n",
    "    'R²': [r['r2'] for r in results.values()],\n",
    "    'MAE': [r['mae'] for r in results.values()],\n",
    "})\n",
    "\n",
    "# Sort by RMSE\n",
    "comparison_df = comparison_df.sort_values('RMSE')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CATE Estimation Benchmark Results\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Predicted vs True CATE\n",
    "for name, result in results.items():\n",
    "    axes[0, 0].scatter(tau_test, result['tau_pred'], alpha=0.5, label=name, s=20)\n",
    "\n",
    "axes[0, 0].plot([tau_test.min(), tau_test.max()], \n",
    "                [tau_test.min(), tau_test.max()], \n",
    "                'k--', label='Perfect prediction')\n",
    "axes[0, 0].set_xlabel('True CATE')\n",
    "axes[0, 0].set_ylabel('Predicted CATE')\n",
    "axes[0, 0].set_title('Predicted vs True CATE')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Error distribution\n",
    "for name, result in results.items():\n",
    "    errors = result['tau_pred'] - tau_test\n",
    "    axes[0, 1].hist(errors, bins=30, alpha=0.5, label=name, edgecolor='black')\n",
    "\n",
    "axes[0, 1].axvline(0, color='k', linestyle='--')\n",
    "axes[0, 1].set_xlabel('Prediction Error')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Error Distribution')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. Performance metrics\n",
    "metrics = ['RMSE', 'R²', 'MAE']\n",
    "x = np.arange(len(results))\n",
    "width = 0.25\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = [results[name][metric.lower().replace('²', '2')] for name in results.keys()]\n",
    "    axes[1, 0].bar(x + i * width, values, width, label=metric)\n",
    "\n",
    "axes[1, 0].set_xlabel('Method')\n",
    "axes[1, 0].set_ylabel('Score')\n",
    "axes[1, 0].set_title('Performance Metrics Comparison')\n",
    "axes[1, 0].set_xticks(x + width)\n",
    "axes[1, 0].set_xticklabels(results.keys(), rotation=45, ha='right')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Absolute error by true CATE\n",
    "for name, result in results.items():\n",
    "    abs_errors = np.abs(result['tau_pred'] - tau_test)\n",
    "    axes[1, 1].scatter(tau_test, abs_errors, alpha=0.5, label=name, s=20)\n",
    "\n",
    "axes[1, 1].set_xlabel('True CATE')\n",
    "axes[1, 1].set_ylabel('Absolute Error')\n",
    "axes[1, 1].set_title('Error vs True CATE')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Representation Analysis\n",
    "\n",
    "Visualize learned representations from Siamese T-Learner and JEPA-Causal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get representations\n",
    "siamese_model = models['Siamese-T']\n",
    "jepa_model = models['JEPA-Causal']\n",
    "\n",
    "z_siamese = siamese_model.get_representations(X_test)\n",
    "z_jepa = jepa_model.get_causal_representations(X_test)\n",
    "\n",
    "print(f\"Siamese representations: {z_siamese.shape}\")\n",
    "print(f\"JEPA representations: {z_jepa.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize representations with UMAP\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Reduce to 2D for visualization\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "z_siamese_2d = tsne.fit_transform(z_siamese)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "z_jepa_2d = tsne.fit_transform(z_jepa)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Siamese representations colored by treatment\n",
    "axes[0, 0].scatter(z_siamese_2d[T_test==0, 0], z_siamese_2d[T_test==0, 1],\n",
    "                   alpha=0.5, label='Control', s=20)\n",
    "axes[0, 0].scatter(z_siamese_2d[T_test==1, 0], z_siamese_2d[T_test==1, 1],\n",
    "                   alpha=0.5, label='Treated', s=20)\n",
    "axes[0, 0].set_title('Siamese T-Learner Representations (by Treatment)')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Siamese representations colored by true CATE\n",
    "scatter = axes[0, 1].scatter(z_siamese_2d[:, 0], z_siamese_2d[:, 1],\n",
    "                             c=tau_test, cmap='RdYlBu_r', s=20, alpha=0.6)\n",
    "axes[0, 1].set_title('Siamese T-Learner Representations (by True CATE)')\n",
    "plt.colorbar(scatter, ax=axes[0, 1], label='True CATE')\n",
    "\n",
    "# JEPA representations colored by treatment\n",
    "axes[1, 0].scatter(z_jepa_2d[T_test==0, 0], z_jepa_2d[T_test==0, 1],\n",
    "                   alpha=0.5, label='Control', s=20)\n",
    "axes[1, 0].scatter(z_jepa_2d[T_test==1, 0], z_jepa_2d[T_test==1, 1],\n",
    "                   alpha=0.5, label='Treated', s=20)\n",
    "axes[1, 0].set_title('JEPA-Causal Representations (by Treatment)')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# JEPA representations colored by true CATE\n",
    "scatter = axes[1, 1].scatter(z_jepa_2d[:, 0], z_jepa_2d[:, 1],\n",
    "                             c=tau_test, cmap='RdYlBu_r', s=20, alpha=0.6)\n",
    "axes[1, 1].set_title('JEPA-Causal Representations (by True CATE)')\n",
    "plt.colorbar(scatter, ax=axes[1, 1], label='True CATE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Key Findings\n",
    "\n",
    "### Expected Results:\n",
    "\n",
    "1. **Siamese T-Learner** should outperform standard T-Learner when:\n",
    "   - Data is high-dimensional (many genes)\n",
    "   - Treatment groups are imbalanced\n",
    "   - Sample size is limited\n",
    "\n",
    "2. **JEPA-Causal** should learn representations that:\n",
    "   - Are invariant to treatment assignment (control/treated overlap)\n",
    "   - Capture effect modifiers (CATE structure visible)\n",
    "   - Provide better generalization\n",
    "\n",
    "3. **Baseline methods** (S/T-Learner) provide strong performance but:\n",
    "   - May struggle with high dimensions\n",
    "   - Don't leverage representation learning\n",
    "   - Less interpretable latent space\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Real data validation**: Test on Perturb-seq or drug response data\n",
    "2. **Architecture search**: Optimize encoder depth, width, regularization\n",
    "3. **Contrastive learning**: Add contrastive loss for better representations\n",
    "4. **Uncertainty quantification**: Add Bayesian layers or ensembles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
