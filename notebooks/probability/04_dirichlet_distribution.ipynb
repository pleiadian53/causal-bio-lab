{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet Distribution: Multivariate Beta\n",
    "\n",
    "The **Dirichlet distribution** is the multivariate generalization of the Beta distribution. While Beta models a single proportion in [0,1], Dirichlet models a **probability vector** that sums to 1.\n",
    "\n",
    "## Why This Matters for Causal ML\n",
    "\n",
    "1. **Cell type proportions** — Model composition of cell populations\n",
    "2. **Treatment assignment probabilities** — Prior for multinomial treatments\n",
    "3. **Heterogeneous treatment effects** — Discover patient subgroups via Dirichlet Process mixtures\n",
    "4. **Topic models / latent states** — LDA-style models for gene programs\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [From Beta to Dirichlet](#1-from-beta-to-dirichlet)\n",
    "2. [Visualization](#2-visualization)\n",
    "3. [The Concentration Parameter](#3-the-concentration-parameter)\n",
    "4. [Dirichlet-Multinomial Conjugacy](#4-dirichlet-multinomial-conjugacy)\n",
    "5. [Applications in Biology](#5-applications-in-biology)\n",
    "6. [Connection to Dirichlet Process](#6-connection-to-dirichlet-process)\n",
    "7. [Quick Reference](#7-quick-reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "# Style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. From Beta to Dirichlet\n",
    "\n",
    "### Beta Distribution (K=2)\n",
    "\n",
    "The Beta distribution models a single probability $\\theta \\in [0, 1]$:\n",
    "\n",
    "$$\\theta \\sim \\text{Beta}(\\alpha, \\beta)$$\n",
    "\n",
    "We can think of this as modeling a 2-category probability vector $(\\theta, 1-\\theta)$.\n",
    "\n",
    "### Dirichlet Distribution (K≥2)\n",
    "\n",
    "The Dirichlet distribution generalizes to K categories:\n",
    "\n",
    "$$\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\ldots, \\theta_K) \\sim \\text{Dirichlet}(\\boldsymbol{\\alpha})$$\n",
    "\n",
    "Where:\n",
    "- $\\boldsymbol{\\alpha} = (\\alpha_1, \\alpha_2, \\ldots, \\alpha_K)$ are concentration parameters\n",
    "- $\\theta_k \\geq 0$ for all k\n",
    "- $\\sum_{k=1}^K \\theta_k = 1$ (probability simplex)\n",
    "\n",
    "### PDF\n",
    "\n",
    "$$p(\\boldsymbol{\\theta} | \\boldsymbol{\\alpha}) = \\frac{\\Gamma(\\sum_k \\alpha_k)}{\\prod_k \\Gamma(\\alpha_k)} \\prod_{k=1}^K \\theta_k^{\\alpha_k - 1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta is Dirichlet with K=2\n",
    "np.random.seed(42)\n",
    "\n",
    "alpha, beta_param = 2, 5\n",
    "\n",
    "# Sample from Beta\n",
    "beta_samples = np.random.beta(alpha, beta_param, 5000)\n",
    "\n",
    "# Sample from Dirichlet with K=2\n",
    "dirichlet_samples = np.random.dirichlet([alpha, beta_param], 5000)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Beta samples\n",
    "axes[0].hist(beta_samples, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "x = np.linspace(0, 1, 200)\n",
    "axes[0].plot(x, stats.beta.pdf(x, alpha, beta_param), 'r-', lw=2, label='Beta PDF')\n",
    "axes[0].set_xlabel('θ')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title(f'Beta({alpha}, {beta_param})')\n",
    "axes[0].legend()\n",
    "\n",
    "# Dirichlet samples (first component)\n",
    "axes[1].hist(dirichlet_samples[:, 0], bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "axes[1].plot(x, stats.beta.pdf(x, alpha, beta_param), 'r-', lw=2, label='Beta PDF')\n",
    "axes[1].set_xlabel('θ₁')\n",
    "axes[1].set_ylabel('Density')\n",
    "axes[1].set_title(f'Dirichlet([{alpha}, {beta_param}]) - First component')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.suptitle('Beta is Dirichlet with K=2', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Beta samples:      mean = {beta_samples.mean():.4f}\")\n",
    "print(f\"Dirichlet θ₁:      mean = {dirichlet_samples[:, 0].mean():.4f}\")\n",
    "print(f\"Theory:            mean = {alpha / (alpha + beta_param):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualization\n",
    "\n",
    "For K=3, the Dirichlet lives on a 2D simplex (triangle). Let's visualize different parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dirichlet_simplex(alpha, ax, n_samples=5000, title=None):\n",
    "    \"\"\"\n",
    "    Plot Dirichlet samples on a 2D simplex (ternary plot).\n",
    "    \n",
    "    For K=3, we project the 3D simplex onto 2D using:\n",
    "    x = θ₂ + θ₃/2\n",
    "    y = θ₃ * sqrt(3)/2\n",
    "    \"\"\"\n",
    "    # Sample from Dirichlet\n",
    "    samples = np.random.dirichlet(alpha, n_samples)\n",
    "    \n",
    "    # Project to 2D (barycentric to Cartesian)\n",
    "    # Vertices of equilateral triangle: (0,0), (1,0), (0.5, sqrt(3)/2)\n",
    "    x = samples[:, 1] + samples[:, 2] / 2\n",
    "    y = samples[:, 2] * np.sqrt(3) / 2\n",
    "    \n",
    "    # Plot\n",
    "    ax.scatter(x, y, alpha=0.3, s=5, c='steelblue')\n",
    "    \n",
    "    # Draw simplex boundary\n",
    "    triangle = plt.Polygon([[0, 0], [1, 0], [0.5, np.sqrt(3)/2]], \n",
    "                           fill=False, edgecolor='black', linewidth=2)\n",
    "    ax.add_patch(triangle)\n",
    "    \n",
    "    # Label vertices\n",
    "    ax.text(-0.05, -0.05, 'θ₁=1', fontsize=10, ha='center')\n",
    "    ax.text(1.05, -0.05, 'θ₂=1', fontsize=10, ha='center')\n",
    "    ax.text(0.5, np.sqrt(3)/2 + 0.05, 'θ₃=1', fontsize=10, ha='center')\n",
    "    \n",
    "    ax.set_xlim(-0.1, 1.1)\n",
    "    ax.set_ylim(-0.1, 1.0)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=12)\n",
    "    else:\n",
    "        ax.set_title(f'Dirichlet({alpha})', fontsize=12)\n",
    "\n",
    "# Different parameter settings\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "params = [\n",
    "    ([1, 1, 1], 'Uniform (α = [1,1,1])'),\n",
    "    ([5, 5, 5], 'Symmetric concentrated (α = [5,5,5])'),\n",
    "    ([0.5, 0.5, 0.5], 'Sparse (α = [0.5,0.5,0.5])'),\n",
    "    ([10, 1, 1], 'Favor θ₁ (α = [10,1,1])'),\n",
    "    ([1, 10, 1], 'Favor θ₂ (α = [1,10,1])'),\n",
    "    ([2, 3, 5], 'Asymmetric (α = [2,3,5])'),\n",
    "]\n",
    "\n",
    "np.random.seed(42)\n",
    "for ax, (alpha, title) in zip(axes.flat, params):\n",
    "    plot_dirichlet_simplex(alpha, ax, title=title)\n",
    "\n",
    "plt.suptitle('Dirichlet Distribution on 2-Simplex (K=3)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "| Parameters | Behavior |\n",
    "|------------|----------|\n",
    "| α = [1,1,1] | Uniform over simplex |\n",
    "| α = [5,5,5] | Concentrated at center (equal proportions) |\n",
    "| α = [0.5,0.5,0.5] | Sparse — samples near vertices/edges |\n",
    "| α = [10,1,1] | Concentrated near θ₁=1 vertex |\n",
    "| Asymmetric α | Concentrated toward higher-α components |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Concentration Parameter\n",
    "\n",
    "Just like Beta, Dirichlet has a **concentration** interpretation:\n",
    "\n",
    "$$\\alpha_0 = \\sum_{k=1}^K \\alpha_k \\quad \\text{(total concentration)}$$\n",
    "\n",
    "We can decompose:\n",
    "- **Base measure**: $\\boldsymbol{\\mu} = \\frac{\\boldsymbol{\\alpha}}{\\alpha_0}$ (expected proportions)\n",
    "- **Concentration**: $\\alpha_0$ (how tightly concentrated around $\\boldsymbol{\\mu}$)\n",
    "\n",
    "This gives the alternative parameterization:\n",
    "$$\\text{Dirichlet}(\\alpha_0 \\cdot \\boldsymbol{\\mu})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of concentration with fixed base measure\n",
    "base_measure = np.array([0.5, 0.3, 0.2])  # Expected proportions\n",
    "concentrations = [1, 5, 20, 100]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "np.random.seed(42)\n",
    "for ax, conc in zip(axes.flat, concentrations):\n",
    "    alpha = conc * base_measure\n",
    "    plot_dirichlet_simplex(alpha, ax, \n",
    "                          title=f'Concentration = {conc}\\nα = [{alpha[0]:.1f}, {alpha[1]:.1f}, {alpha[2]:.1f}]')\n",
    "    \n",
    "    # Mark the expected value\n",
    "    exp_x = base_measure[1] + base_measure[2] / 2\n",
    "    exp_y = base_measure[2] * np.sqrt(3) / 2\n",
    "    ax.scatter([exp_x], [exp_y], c='red', s=100, marker='*', zorder=5, label='E[θ]')\n",
    "\n",
    "plt.suptitle(f'Effect of Concentration (Base measure = {base_measure})', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"As concentration increases:\")\n",
    "print(\"  - Samples concentrate around the expected value\")\n",
    "print(\"  - Variance decreases\")\n",
    "print(\"  - Distribution becomes more 'certain'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantify the effect of concentration on variance\n",
    "base_measure = np.array([0.5, 0.3, 0.2])\n",
    "concentrations = [1, 2, 5, 10, 20, 50, 100, 200]\n",
    "\n",
    "variances = []\n",
    "for conc in concentrations:\n",
    "    alpha = conc * base_measure\n",
    "    samples = np.random.dirichlet(alpha, 10000)\n",
    "    # Variance of first component\n",
    "    variances.append(samples[:, 0].var())\n",
    "\n",
    "# Theoretical variance: Var(θ_k) = μ_k(1-μ_k) / (α_0 + 1)\n",
    "theoretical_var = [base_measure[0] * (1 - base_measure[0]) / (c + 1) for c in concentrations]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.plot(concentrations, variances, 'bo-', lw=2, markersize=8, label='Empirical')\n",
    "ax.plot(concentrations, theoretical_var, 'r--', lw=2, label='Theoretical')\n",
    "\n",
    "ax.set_xlabel('Concentration (α₀)')\n",
    "ax.set_ylabel('Variance of θ₁')\n",
    "ax.set_title('Variance Decreases with Concentration\\nVar(θₖ) = μₖ(1-μₖ) / (α₀ + 1)')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dirichlet Moments\n",
    "\n",
    "**Mean:**\n",
    "$$\\mathbb{E}[\\theta_k] = \\frac{\\alpha_k}{\\alpha_0} = \\mu_k$$\n",
    "\n",
    "**Variance:**\n",
    "$$\\text{Var}(\\theta_k) = \\frac{\\mu_k(1 - \\mu_k)}{\\alpha_0 + 1}$$\n",
    "\n",
    "**Covariance:**\n",
    "$$\\text{Cov}(\\theta_j, \\theta_k) = \\frac{-\\mu_j \\mu_k}{\\alpha_0 + 1} \\quad (j \\neq k)$$\n",
    "\n",
    "Note: Components are **negatively correlated** (if one goes up, others must go down to sum to 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dirichlet-Multinomial Conjugacy\n",
    "\n",
    "Just as Beta is conjugate to Binomial, **Dirichlet is conjugate to Multinomial**:\n",
    "\n",
    "$$\\text{Dirichlet prior} + \\text{Multinomial data} = \\text{Dirichlet posterior}$$\n",
    "\n",
    "### Update Rule\n",
    "\n",
    "If we observe counts $\\mathbf{n} = (n_1, n_2, \\ldots, n_K)$:\n",
    "\n",
    "$$\\boldsymbol{\\alpha}_{\\text{posterior}} = \\boldsymbol{\\alpha}_{\\text{prior}} + \\mathbf{n}$$\n",
    "\n",
    "That's it! Just add the counts to each α."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian updating example: Cell type composition\n",
    "\n",
    "# Prior: We expect roughly equal proportions of 3 cell types\n",
    "prior_alpha = np.array([2, 2, 2])  # Weak prior\n",
    "\n",
    "# Data: We observe cell type counts\n",
    "observed_counts = np.array([45, 30, 25])  # 100 cells total\n",
    "\n",
    "# Posterior\n",
    "posterior_alpha = prior_alpha + observed_counts\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Prior\n",
    "plot_dirichlet_simplex(prior_alpha, axes[0], \n",
    "                       title=f'Prior: Dirichlet({list(prior_alpha)})')\n",
    "\n",
    "# Data visualization (as a point)\n",
    "data_prop = observed_counts / observed_counts.sum()\n",
    "data_x = data_prop[1] + data_prop[2] / 2\n",
    "data_y = data_prop[2] * np.sqrt(3) / 2\n",
    "\n",
    "axes[1].scatter([data_x], [data_y], c='green', s=200, marker='X', zorder=5)\n",
    "triangle = plt.Polygon([[0, 0], [1, 0], [0.5, np.sqrt(3)/2]], \n",
    "                       fill=False, edgecolor='black', linewidth=2)\n",
    "axes[1].add_patch(triangle)\n",
    "axes[1].text(-0.05, -0.05, 'Type A', fontsize=10, ha='center')\n",
    "axes[1].text(1.05, -0.05, 'Type B', fontsize=10, ha='center')\n",
    "axes[1].text(0.5, np.sqrt(3)/2 + 0.05, 'Type C', fontsize=10, ha='center')\n",
    "axes[1].set_xlim(-0.1, 1.1)\n",
    "axes[1].set_ylim(-0.1, 1.0)\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title(f'Data: {observed_counts[0]}A, {observed_counts[1]}B, {observed_counts[2]}C\\n'\n",
    "                  f'Proportions: [{data_prop[0]:.2f}, {data_prop[1]:.2f}, {data_prop[2]:.2f}]')\n",
    "\n",
    "# Posterior\n",
    "plot_dirichlet_simplex(posterior_alpha, axes[2],\n",
    "                       title=f'Posterior: Dirichlet({list(posterior_alpha)})')\n",
    "# Mark posterior mean\n",
    "post_mean = posterior_alpha / posterior_alpha.sum()\n",
    "post_x = post_mean[1] + post_mean[2] / 2\n",
    "post_y = post_mean[2] * np.sqrt(3) / 2\n",
    "axes[2].scatter([post_x], [post_y], c='red', s=100, marker='*', zorder=5)\n",
    "\n",
    "plt.suptitle('Dirichlet-Multinomial Conjugacy: Cell Type Composition', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Prior:\")\n",
    "print(f\"  α = {prior_alpha}\")\n",
    "print(f\"  E[θ] = {prior_alpha / prior_alpha.sum()}\")\n",
    "\n",
    "print(f\"\\nData: {observed_counts} (n={observed_counts.sum()})\")\n",
    "\n",
    "print(f\"\\nPosterior:\")\n",
    "print(f\"  α = {posterior_alpha}\")\n",
    "print(f\"  E[θ] = {posterior_alpha / posterior_alpha.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Applications in Biology\n",
    "\n",
    "### Application 1: Cell Type Deconvolution\n",
    "\n",
    "Given bulk RNA-seq, estimate the proportion of each cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating cell type deconvolution uncertainty\n",
    "np.random.seed(42)\n",
    "\n",
    "# True proportions (unknown in practice)\n",
    "true_proportions = np.array([0.50, 0.30, 0.15, 0.05])  # 4 cell types\n",
    "cell_types = ['T cells', 'B cells', 'Macrophages', 'NK cells']\n",
    "\n",
    "# After deconvolution, we have posterior Dirichlet\n",
    "# (In practice, this comes from the algorithm)\n",
    "# Higher concentration = more confident estimate\n",
    "concentration = 50\n",
    "posterior_alpha = concentration * true_proportions + np.random.randn(4) * 2\n",
    "posterior_alpha = np.maximum(posterior_alpha, 1)  # Ensure positive\n",
    "\n",
    "# Sample from posterior to get uncertainty\n",
    "n_samples = 10000\n",
    "proportion_samples = np.random.dirichlet(posterior_alpha, n_samples)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for i, (ax, cell_type) in enumerate(zip(axes.flat, cell_types)):\n",
    "    samples = proportion_samples[:, i]\n",
    "    \n",
    "    ax.hist(samples, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(true_proportions[i], color='red', linestyle='--', lw=2, \n",
    "               label=f'True = {true_proportions[i]:.2f}')\n",
    "    ax.axvline(samples.mean(), color='green', linestyle='-', lw=2,\n",
    "               label=f'Mean = {samples.mean():.3f}')\n",
    "    \n",
    "    # 95% CI\n",
    "    ci_low, ci_high = np.percentile(samples, [2.5, 97.5])\n",
    "    ax.axvspan(ci_low, ci_high, alpha=0.2, color='green',\n",
    "               label=f'95% CI: [{ci_low:.3f}, {ci_high:.3f}]')\n",
    "    \n",
    "    ax.set_xlabel('Proportion')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(f'{cell_type}')\n",
    "    ax.legend(fontsize=9)\n",
    "\n",
    "plt.suptitle('Cell Type Deconvolution: Posterior Uncertainty', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application 2: Treatment Response Subgroups\n",
    "\n",
    "In causal ML, we might model the probability of belonging to different response subgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatment response subgroups\n",
    "np.random.seed(42)\n",
    "\n",
    "# Prior: We expect most patients to be moderate responders\n",
    "# Subgroups: Non-responder, Low, Moderate, High responder\n",
    "subgroups = ['Non-responder', 'Low', 'Moderate', 'High']\n",
    "prior_alpha = np.array([1, 2, 5, 2])  # Prior favors moderate\n",
    "\n",
    "# After observing trial data\n",
    "observed_counts = np.array([15, 25, 40, 20])  # 100 patients\n",
    "posterior_alpha = prior_alpha + observed_counts\n",
    "\n",
    "# Sample from prior and posterior\n",
    "n_samples = 10000\n",
    "prior_samples = np.random.dirichlet(prior_alpha, n_samples)\n",
    "posterior_samples = np.random.dirichlet(posterior_alpha, n_samples)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Prior\n",
    "bp1 = axes[0].boxplot([prior_samples[:, i] for i in range(4)], \n",
    "                       labels=subgroups, patch_artist=True)\n",
    "colors = ['#e74c3c', '#f39c12', '#2ecc71', '#3498db']\n",
    "for patch, color in zip(bp1['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "axes[0].set_ylabel('Proportion')\n",
    "axes[0].set_title(f'Prior: Dirichlet({list(prior_alpha)})')\n",
    "axes[0].set_ylim(0, 0.8)\n",
    "\n",
    "# Posterior\n",
    "bp2 = axes[1].boxplot([posterior_samples[:, i] for i in range(4)],\n",
    "                       labels=subgroups, patch_artist=True)\n",
    "for patch, color in zip(bp2['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "axes[1].set_ylabel('Proportion')\n",
    "axes[1].set_title(f'Posterior: Dirichlet({list(posterior_alpha)})')\n",
    "axes[1].set_ylim(0, 0.8)\n",
    "\n",
    "# Add observed proportions\n",
    "obs_prop = observed_counts / observed_counts.sum()\n",
    "axes[1].scatter(range(1, 5), obs_prop, color='red', s=100, marker='*', \n",
    "                zorder=5, label='Observed')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.suptitle('Treatment Response Subgroups: Bayesian Inference', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Posterior summary:\")\n",
    "for i, subgroup in enumerate(subgroups):\n",
    "    mean = posterior_samples[:, i].mean()\n",
    "    ci_low, ci_high = np.percentile(posterior_samples[:, i], [2.5, 97.5])\n",
    "    print(f\"  {subgroup:15s}: {mean:.3f} [{ci_low:.3f}, {ci_high:.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Connection to Dirichlet Process\n",
    "\n",
    "The Dirichlet distribution is finite-dimensional. The **Dirichlet Process (DP)** extends this to infinite dimensions:\n",
    "\n",
    "| Dirichlet Distribution | Dirichlet Process |\n",
    "|------------------------|-------------------|\n",
    "| Fixed K categories | Infinite categories |\n",
    "| $\\boldsymbol{\\theta} \\sim \\text{Dir}(\\boldsymbol{\\alpha})$ | $G \\sim \\text{DP}(\\alpha_0, G_0)$ |\n",
    "| Concentration: $\\alpha_0 = \\sum_k \\alpha_k$ | Concentration: $\\alpha_0$ |\n",
    "| Base measure: $\\boldsymbol{\\mu} = \\boldsymbol{\\alpha}/\\alpha_0$ | Base measure: $G_0$ |\n",
    "\n",
    "### Why DP Matters for Causal ML\n",
    "\n",
    "1. **Unknown number of subgroups** — DP lets data determine K\n",
    "2. **Heterogeneous treatment effects** — Different subgroups have different CATEs\n",
    "3. **Flexible outcome modeling** — DP mixture models for $Y(0)$ and $Y(1)$\n",
    "4. **Clustering patients** — Discover latent subpopulations\n",
    "\n",
    "### Stick-Breaking Construction (Preview)\n",
    "\n",
    "The DP can be constructed via \"stick-breaking\":\n",
    "\n",
    "$$\\pi_k = V_k \\prod_{j=1}^{k-1}(1 - V_j), \\quad V_k \\sim \\text{Beta}(1, \\alpha_0)$$\n",
    "\n",
    "This connects back to Beta! The concentration $\\alpha_0$ controls how quickly the stick \"breaks\" (how many clusters we get)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview: Stick-breaking construction\n",
    "def stick_breaking(alpha, K=20):\n",
    "    \"\"\"Generate stick-breaking weights.\"\"\"\n",
    "    betas = np.random.beta(1, alpha, K)\n",
    "    weights = np.zeros(K)\n",
    "    remaining = 1.0\n",
    "    for k in range(K):\n",
    "        weights[k] = betas[k] * remaining\n",
    "        remaining *= (1 - betas[k])\n",
    "    return weights\n",
    "\n",
    "np.random.seed(42)\n",
    "concentrations = [0.5, 1, 5, 20]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "for ax, alpha in zip(axes.flat, concentrations):\n",
    "    # Multiple draws\n",
    "    for _ in range(5):\n",
    "        weights = stick_breaking(alpha, K=20)\n",
    "        ax.bar(range(1, 21), weights, alpha=0.3, width=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Component k')\n",
    "    ax.set_ylabel('Weight πₖ')\n",
    "    ax.set_title(f'Concentration α₀ = {alpha}')\n",
    "    ax.set_xlim(0, 21)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "plt.suptitle('Stick-Breaking: Effect of Concentration\\n(Low α → few clusters, High α → many clusters)', \n",
    "             fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Concentration controls cluster structure:\")\n",
    "print(\"  Low α₀ (e.g., 0.5): Few dominant clusters\")\n",
    "print(\"  High α₀ (e.g., 20): Many small clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quick Reference\n",
    "\n",
    "### Key Formulas\n",
    "\n",
    "```\n",
    "Dirichlet(α₁, α₂, ..., αₖ)\n",
    "\n",
    "Concentration: α₀ = Σαₖ\n",
    "Base measure:  μₖ = αₖ / α₀\n",
    "\n",
    "Mean:     E[θₖ] = αₖ / α₀\n",
    "Variance: Var(θₖ) = μₖ(1-μₖ) / (α₀ + 1)\n",
    "\n",
    "Bayesian update (Multinomial likelihood):\n",
    "  Prior: Dirichlet(α)\n",
    "  Data: counts n = (n₁, n₂, ..., nₖ)\n",
    "  Posterior: Dirichlet(α + n)\n",
    "```\n",
    "\n",
    "### Special Cases\n",
    "\n",
    "| α | Distribution |\n",
    "|---|-------------|\n",
    "| [1, 1, ..., 1] | Uniform on simplex |\n",
    "| [α, α, ..., α] | Symmetric Dirichlet |\n",
    "| K=2 | Beta distribution |\n",
    "\n",
    "### Connections\n",
    "\n",
    "- **Beta** = Dirichlet with K=2\n",
    "- **Dirichlet Process** = infinite-dimensional Dirichlet\n",
    "- **LDA** = Dirichlet prior on topic proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def dirichlet_summary(alpha):\n",
    "    \"\"\"Print summary statistics for a Dirichlet distribution.\"\"\"\n",
    "    alpha = np.array(alpha)\n",
    "    alpha_0 = alpha.sum()\n",
    "    mu = alpha / alpha_0\n",
    "    \n",
    "    print(f\"Dirichlet({list(alpha)}) Summary:\")\n",
    "    print(f\"  Concentration (α₀): {alpha_0:.2f}\")\n",
    "    print(f\"  Base measure (μ):   {mu}\")\n",
    "    print(f\"\\n  Component statistics:\")\n",
    "    for k in range(len(alpha)):\n",
    "        var_k = mu[k] * (1 - mu[k]) / (alpha_0 + 1)\n",
    "        print(f\"    θ_{k+1}: E={mu[k]:.4f}, Var={var_k:.6f}\")\n",
    "\n",
    "# Example\n",
    "dirichlet_summary([2, 3, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "The Dirichlet distribution is essential for:\n",
    "\n",
    "1. **Modeling probability vectors** (compositions that sum to 1)\n",
    "2. **Bayesian inference** as conjugate prior for multinomial data\n",
    "3. **Understanding concentration** — the key parameter controlling uncertainty\n",
    "4. **Foundation for Dirichlet Process** — nonparametric Bayesian methods\n",
    "\n",
    "**For causal ML:**\n",
    "- Model cell type proportions in deconvolution\n",
    "- Prior for treatment response subgroup proportions\n",
    "- Foundation for DP mixture models that discover heterogeneous treatment effects\n",
    "\n",
    "**Next:** See `05_dirichlet_process.ipynb` for the infinite-dimensional extension and its applications to clustering and causal inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
